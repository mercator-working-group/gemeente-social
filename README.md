# gemeente-social
An analysis of social media presence on official municipal websites of the Netherlands

## Overview
`gemeente-social` is a repository for investigative and analytical work specific to the prevalence of social media resources appearing on official websites belonging to municipalities in the Netherlands. This repository contains parameters used in this investigation and analyses performed to provide aggregate and anecdotal reporting on the usage of third-party communication and social platforms by governmental municipal parties.

## Table of Contents: 
  - analysis
    - notebooks
        * Contains investigative methodology of OpenWPM result set and graphical exploration
    - derived_datasets
        * Saved output from analysis relevant to journalistic work packages
  - seed_list
      * Contains csv files with base site lists for OpenWPM crawls

## Dependencies
The instrumentation of the crawl used to collect data fro municipal websites for the gemeente-social project accomplished using a [custom fork](https://github.com/mercator-working-group/OpenWPM) of the [OpenWPM](https://github.com/mozilla/OpenWPM) web privacy measurement framework, developed by Steven Engelhardt at [Princeton University](https://webtap.princeton.edu/), currently hosted and maintained by [Mozilla](mozilla.org). 

## Workflow: region agnostic examination of private communication infrastructure by governmental entities

  - Accept an arbitrary seed list of government websites
  - Determine one-depth a-tag linkage structure with a shallow preliminary crawl
  - Perform a comprehensive crawl using OpenWPM to instrument JavaScript events at page visit
  - Parse OpenWPM data into Pandas table
  - Match against an arbitrary list
  - Identify specific tracking pixels and potential fingerprinting attacks focussing on third-party loaded resources.
  - Generate a report of third-party resources and tracking activity occurring per page (from originally provided seed-list).

## Analyses
The primary analysis outputs were generated by the [cookie-discovery](https://github.com/mercator-working-group/gemeente-social/blob/master/analysis/notebooks/cookie-discovery.ipynb) notebook. 

  - Since the notebook loads data for all pages visited (i.e. municipal landing pages, and all also all outbound links), the
    early cells reduce the dataset to only the parent pages themselves. 
      * *Note*: This means only the landing pages themselves are analyzed, not outbound links or sub pages on the top level domain
  - The data from the OpenWPM javascript and site_visits tables  is then joined on visit_id, so that every javascript entry has it's
    corresponding site_visit details
  - There is a general overview of the javascript event data's content, structure and distribution inspecting
  - In cell [9] the dataset is reduced to only javascript events relating to _window.document.cookie_ activity
      * The result of which is a value count of the origin url of the javascript code executed for each _window.document.cookie_ entry
  - In cell [10] the popular domains that load javascript and interact with cookies are split up into get and set actions to roughly      gauge the overall dimensions of these actions
  - In cell [12] the dataset is filtered to javascript actions committed by code loaded from _facebook.net_ and presented
  - The remainder of the notebook investigates the common contents (keys/values) of cookies in the dataset presenting a potential 
    waypoint for further analysis 

The analysis undertaken in [cookie-discovery-full](https://github.com/mercator-working-group/gemeente-social/blob/master/analysis/notebooks/cookie-discovery-full.ipynb) begins by analyzing the entire javascript dataset, that is the crawl results from all municipal landing pages as well as data from all outbound links. This is then reduced to a focused dataset described below:
  - In cell [14] the dataset is filtered by two criteria:
    1) Domains that had some javascript loaded from domains associated with social media:
      - `social_sites_js_analysis = js_analysis[ js_analysis['script_url_tld'].str.contains('|'.join(SM_FLDS), na=False) ]`
    2) Javascript events whose parent_url top level domain matches the site_visit url top level domain (this in effect means only pages   that exist on municipal domains)
      - `only_gementee_sub_pages = ss_js_analysis.loc[ss_js_analysis['site_url_tld'] == ss_js_analysis['parent_url_tld']]`


# FAQ

### When was the data used in this analysis collected?
The most recent full pre-crawl and comprehensive (OpenWPM) crawls were executed on May 29th, 2019 (UTC+2)
The crawl visited every site site listed here [gemeente-out-full.json](https://github.com/mercator-working-group/gemeente-social/blob/50572fac8deb02e55f129cd732a479f899f61432/gemeente-out-full.json) - it is structured so that the municipal landing page, is the key of each entry, and the list of values are all href links on that page see [parse_utils.py](https://github.com/mercator-working-group/gemeente-social/blob/master/parse_utils.py)

### What does it mean when a municipal website executes code from a third-party source? 
In the case of third-party cookies, the use of a cookie from a third-party (that means a top level domain different than the one of the page you are visiting)  _may_ be a source of privacy concerns. For example, tracker cookies can be used to identify which websites you've visited and what actions you have performed during a web page visit. 
In the case of arbitrary JavaScript executed from third-party domains this means that code being hosted at a different location than the website you are visiting is being executed. This can include things like website analytics services, font or styling tools, or desirable complex services. However, the execution of third-party JavasScript can also be used to transfer sensitive information with a party besides the owner of the website. Third-party scripts can report back data that you weren't aware of and are frequently used in online tracking and advertisement. Unfortunately, it is often very difficult (or impossible) to tell what the third-party script is doing until it has been executed. For this reason we treat all third=party code execution as a [privacy risk](https://css-tricks.com/potential-dangers-of-third-party-javascript/).

### Why are some pages' social media links not listed/counted in the analysis, but when I visit those pages in my web browser I see links to social media?
We believe that the count of total social media links on municipal websites that we report here is an underestimate. There are many reasons why our crawl methodology can miss outbound links. For top-level aggregates before we pass links to OpenWPM we only count <href> tags, therefore, links to social media generated dynamically or placed in frames may be missed. It is also possible that a municipal website is not correctly parsed and various processing errors are possible. For the purpose of this analysis we prefer to miss a link than to make false claims about the behaviour of any municipal website so we err on the side of caution, this may mean that some outbound social media accounts are not counted and also not subsequently passed to OpenWPM for deeper analysis. 
